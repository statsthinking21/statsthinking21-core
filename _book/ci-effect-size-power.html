<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 10 Quantifying effects and designing studies | Statistical Thinking for the 21st Century</title>
  <meta name="description" content="A book about statistics." />
  <meta name="generator" content="bookdown 0.31 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 10 Quantifying effects and designing studies | Statistical Thinking for the 21st Century" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="A book about statistics." />
  <meta name="github-repo" content="poldrack/psych10-book" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 10 Quantifying effects and designing studies | Statistical Thinking for the 21st Century" />
  
  <meta name="twitter:description" content="A book about statistics." />
  

<meta name="author" content="Copyright 2019 Russell A. Poldrack" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="hypothesis-testing.html"/>
<link rel="next" href="bayesian-statistics.html"/>
<script src="book_assets/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="book_assets/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="book_assets/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="book_assets/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="book_assets/anchor-sections-1.1.0/anchor-sections.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-129414074-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-129414074-1');
</script>



<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="0.1" data-path="index.html"><a href="index.html#why-does-this-book-exist"><i class="fa fa-check"></i><b>0.1</b> Why does this book exist?</a></li>
<li class="chapter" data-level="0.2" data-path="index.html"><a href="index.html#the-golden-age-of-data"><i class="fa fa-check"></i><b>0.2</b> The golden age of data</a></li>
<li class="chapter" data-level="0.3" data-path="index.html"><a href="index.html#the-importance-of-doing-statistics"><i class="fa fa-check"></i><b>0.3</b> The importance of doing statistics</a></li>
<li class="chapter" data-level="0.4" data-path="index.html"><a href="index.html#an-open-source-book"><i class="fa fa-check"></i><b>0.4</b> An open source book</a></li>
<li class="chapter" data-level="0.5" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i><b>0.5</b> Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#what-is-statistical-thinking"><i class="fa fa-check"></i><b>1.1</b> What is statistical thinking?</a></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#dealing-with-statistics-anxiety"><i class="fa fa-check"></i><b>1.2</b> Dealing with statistics anxiety</a></li>
<li class="chapter" data-level="1.3" data-path="introduction.html"><a href="introduction.html#what-can-statistics-do-for-us"><i class="fa fa-check"></i><b>1.3</b> What can statistics do for us?</a></li>
<li class="chapter" data-level="1.4" data-path="introduction.html"><a href="introduction.html#the-big-ideas-of-statistics"><i class="fa fa-check"></i><b>1.4</b> The big ideas of statistics</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="introduction.html"><a href="introduction.html#learning-from-data"><i class="fa fa-check"></i><b>1.4.1</b> Learning from data</a></li>
<li class="chapter" data-level="1.4.2" data-path="introduction.html"><a href="introduction.html#aggregation"><i class="fa fa-check"></i><b>1.4.2</b> Aggregation</a></li>
<li class="chapter" data-level="1.4.3" data-path="introduction.html"><a href="introduction.html#uncertainty"><i class="fa fa-check"></i><b>1.4.3</b> Uncertainty</a></li>
<li class="chapter" data-level="1.4.4" data-path="introduction.html"><a href="introduction.html#sampling-from-a-population"><i class="fa fa-check"></i><b>1.4.4</b> Sampling from a population</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="introduction.html"><a href="introduction.html#causality-and-statistics"><i class="fa fa-check"></i><b>1.5</b> Causality and statistics</a></li>
<li class="chapter" data-level="1.6" data-path="introduction.html"><a href="introduction.html#learning-objectives"><i class="fa fa-check"></i><b>1.6</b> Learning objectives</a></li>
<li class="chapter" data-level="1.7" data-path="introduction.html"><a href="introduction.html#suggested-readings"><i class="fa fa-check"></i><b>1.7</b> Suggested readings</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="working-with-data.html"><a href="working-with-data.html"><i class="fa fa-check"></i><b>2</b> Working with data</a>
<ul>
<li class="chapter" data-level="2.1" data-path="working-with-data.html"><a href="working-with-data.html#what-are-data"><i class="fa fa-check"></i><b>2.1</b> What are data?</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="working-with-data.html"><a href="working-with-data.html#qualitative-data"><i class="fa fa-check"></i><b>2.1.1</b> Qualitative data</a></li>
<li class="chapter" data-level="2.1.2" data-path="working-with-data.html"><a href="working-with-data.html#quantitative-data"><i class="fa fa-check"></i><b>2.1.2</b> Quantitative data</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="working-with-data.html"><a href="working-with-data.html#discrete-versus-continuous-measurements"><i class="fa fa-check"></i><b>2.2</b> Discrete versus continuous measurements</a></li>
<li class="chapter" data-level="2.3" data-path="working-with-data.html"><a href="working-with-data.html#what-makes-a-good-measurement"><i class="fa fa-check"></i><b>2.3</b> What makes a good measurement?</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="working-with-data.html"><a href="working-with-data.html#reliability"><i class="fa fa-check"></i><b>2.3.1</b> Reliability</a></li>
<li class="chapter" data-level="2.3.2" data-path="working-with-data.html"><a href="working-with-data.html#validity"><i class="fa fa-check"></i><b>2.3.2</b> Validity</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="working-with-data.html"><a href="working-with-data.html#learning-objectives-1"><i class="fa fa-check"></i><b>2.4</b> Learning Objectives</a></li>
<li class="chapter" data-level="2.5" data-path="working-with-data.html"><a href="working-with-data.html#suggested-readings-1"><i class="fa fa-check"></i><b>2.5</b> Suggested readings</a></li>
<li class="chapter" data-level="2.6" data-path="working-with-data.html"><a href="working-with-data.html#appendix"><i class="fa fa-check"></i><b>2.6</b> Appendix</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="working-with-data.html"><a href="working-with-data.html#scales-of-measurement"><i class="fa fa-check"></i><b>2.6.1</b> Scales of measurement</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="summarizing-data.html"><a href="summarizing-data.html"><i class="fa fa-check"></i><b>3</b> Summarizing data</a>
<ul>
<li class="chapter" data-level="3.1" data-path="summarizing-data.html"><a href="summarizing-data.html#why-summarize-data"><i class="fa fa-check"></i><b>3.1</b> Why summarize data?</a></li>
<li class="chapter" data-level="3.2" data-path="summarizing-data.html"><a href="summarizing-data.html#summarizing-data-using-tables"><i class="fa fa-check"></i><b>3.2</b> Summarizing data using tables</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="summarizing-data.html"><a href="summarizing-data.html#frequency-distributions"><i class="fa fa-check"></i><b>3.2.1</b> Frequency distributions</a></li>
<li class="chapter" data-level="3.2.2" data-path="summarizing-data.html"><a href="summarizing-data.html#cumulative-distributions"><i class="fa fa-check"></i><b>3.2.2</b> Cumulative distributions</a></li>
<li class="chapter" data-level="3.2.3" data-path="summarizing-data.html"><a href="summarizing-data.html#plotting-histograms"><i class="fa fa-check"></i><b>3.2.3</b> Plotting histograms</a></li>
<li class="chapter" data-level="3.2.4" data-path="summarizing-data.html"><a href="summarizing-data.html#histogram-bins"><i class="fa fa-check"></i><b>3.2.4</b> Histogram bins</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="summarizing-data.html"><a href="summarizing-data.html#idealized-representations-of-distributions"><i class="fa fa-check"></i><b>3.3</b> Idealized representations of distributions</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="summarizing-data.html"><a href="summarizing-data.html#skewness"><i class="fa fa-check"></i><b>3.3.1</b> Skewness</a></li>
<li class="chapter" data-level="3.3.2" data-path="summarizing-data.html"><a href="summarizing-data.html#long-tailed-distributions"><i class="fa fa-check"></i><b>3.3.2</b> Long-tailed distributions</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="summarizing-data.html"><a href="summarizing-data.html#learning-objectives-2"><i class="fa fa-check"></i><b>3.4</b> Learning objectives</a></li>
<li class="chapter" data-level="3.5" data-path="summarizing-data.html"><a href="summarizing-data.html#suggested-readings-2"><i class="fa fa-check"></i><b>3.5</b> Suggested readings</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="data-visualization.html"><a href="data-visualization.html"><i class="fa fa-check"></i><b>4</b> Data Visualization</a>
<ul>
<li class="chapter" data-level="4.1" data-path="data-visualization.html"><a href="data-visualization.html#anatomy-of-a-plot"><i class="fa fa-check"></i><b>4.1</b> Anatomy of a plot</a></li>
<li class="chapter" data-level="4.2" data-path="data-visualization.html"><a href="data-visualization.html#principles-of-good-visualization"><i class="fa fa-check"></i><b>4.2</b> Principles of good visualization</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="data-visualization.html"><a href="data-visualization.html#show-the-data-and-make-them-stand-out"><i class="fa fa-check"></i><b>4.2.1</b> Show the data and make them stand out</a></li>
<li class="chapter" data-level="4.2.2" data-path="data-visualization.html"><a href="data-visualization.html#maximize-the-dataink-ratio"><i class="fa fa-check"></i><b>4.2.2</b> Maximize the data/ink ratio</a></li>
<li class="chapter" data-level="4.2.3" data-path="data-visualization.html"><a href="data-visualization.html#avoid-chartjunk"><i class="fa fa-check"></i><b>4.2.3</b> Avoid chartjunk</a></li>
<li class="chapter" data-level="4.2.4" data-path="data-visualization.html"><a href="data-visualization.html#avoid-distorting-the-data"><i class="fa fa-check"></i><b>4.2.4</b> Avoid distorting the data</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="data-visualization.html"><a href="data-visualization.html#accommodating-human-limitations"><i class="fa fa-check"></i><b>4.3</b> Accommodating human limitations</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="data-visualization.html"><a href="data-visualization.html#perceptual-limitations"><i class="fa fa-check"></i><b>4.3.1</b> Perceptual limitations</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="data-visualization.html"><a href="data-visualization.html#correcting-for-other-factors"><i class="fa fa-check"></i><b>4.4</b> Correcting for other factors</a></li>
<li class="chapter" data-level="4.5" data-path="data-visualization.html"><a href="data-visualization.html#learning-objectives-3"><i class="fa fa-check"></i><b>4.5</b> Learning objectives</a></li>
<li class="chapter" data-level="4.6" data-path="data-visualization.html"><a href="data-visualization.html#suggested-readings-and-videos"><i class="fa fa-check"></i><b>4.6</b> Suggested readings and videos</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="fitting-models.html"><a href="fitting-models.html"><i class="fa fa-check"></i><b>5</b> Fitting models to data</a>
<ul>
<li class="chapter" data-level="5.1" data-path="fitting-models.html"><a href="fitting-models.html#what-is-a-model"><i class="fa fa-check"></i><b>5.1</b> What is a model?</a></li>
<li class="chapter" data-level="5.2" data-path="fitting-models.html"><a href="fitting-models.html#statistical-modeling-an-example"><i class="fa fa-check"></i><b>5.2</b> Statistical modeling: An example</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="fitting-models.html"><a href="fitting-models.html#improving-our-model"><i class="fa fa-check"></i><b>5.2.1</b> Improving our model</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="fitting-models.html"><a href="fitting-models.html#what-makes-a-model-good"><i class="fa fa-check"></i><b>5.3</b> What makes a model “good”?</a></li>
<li class="chapter" data-level="5.4" data-path="fitting-models.html"><a href="fitting-models.html#overfitting"><i class="fa fa-check"></i><b>5.4</b> Can a model be too good?</a></li>
<li class="chapter" data-level="5.5" data-path="fitting-models.html"><a href="fitting-models.html#summarizing-data-using-the-mean"><i class="fa fa-check"></i><b>5.5</b> Summarizing data using the mean</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="fitting-models.html"><a href="fitting-models.html#summarizing-data-robustly-using-the-median"><i class="fa fa-check"></i><b>5.5.1</b> Summarizing data robustly using the median</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="fitting-models.html"><a href="fitting-models.html#the-mode"><i class="fa fa-check"></i><b>5.6</b> The mode</a></li>
<li class="chapter" data-level="5.7" data-path="fitting-models.html"><a href="fitting-models.html#variability-how-well-does-the-mean-fit-the-data"><i class="fa fa-check"></i><b>5.7</b> Variability: How well does the mean fit the data?</a></li>
<li class="chapter" data-level="5.8" data-path="fitting-models.html"><a href="fitting-models.html#using-simulations-to-understand-statistics"><i class="fa fa-check"></i><b>5.8</b> Using simulations to understand statistics</a></li>
<li class="chapter" data-level="5.9" data-path="fitting-models.html"><a href="fitting-models.html#z-scores"><i class="fa fa-check"></i><b>5.9</b> Z-scores</a>
<ul>
<li class="chapter" data-level="5.9.1" data-path="fitting-models.html"><a href="fitting-models.html#interpreting-z-scores"><i class="fa fa-check"></i><b>5.9.1</b> Interpreting Z-scores</a></li>
<li class="chapter" data-level="5.9.2" data-path="fitting-models.html"><a href="fitting-models.html#standardized-scores"><i class="fa fa-check"></i><b>5.9.2</b> Standardized scores</a></li>
</ul></li>
<li class="chapter" data-level="5.10" data-path="fitting-models.html"><a href="fitting-models.html#learning-objectives-4"><i class="fa fa-check"></i><b>5.10</b> Learning objectives</a></li>
<li class="chapter" data-level="5.11" data-path="fitting-models.html"><a href="fitting-models.html#appendix-1"><i class="fa fa-check"></i><b>5.11</b> Appendix</a>
<ul>
<li class="chapter" data-level="5.11.1" data-path="fitting-models.html"><a href="fitting-models.html#proof-that-the-sum-of-errors-from-the-mean-is-zero"><i class="fa fa-check"></i><b>5.11.1</b> Proof that the sum of errors from the Mean is zero</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>6</b> Probability</a>
<ul>
<li class="chapter" data-level="6.1" data-path="probability.html"><a href="probability.html#what-is-probability"><i class="fa fa-check"></i><b>6.1</b> What is probability?</a></li>
<li class="chapter" data-level="6.2" data-path="probability.html"><a href="probability.html#how-do-we-determine-probabilities"><i class="fa fa-check"></i><b>6.2</b> How do we determine probabilities?</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="probability.html"><a href="probability.html#personal-belief"><i class="fa fa-check"></i><b>6.2.1</b> Personal belief</a></li>
<li class="chapter" data-level="6.2.2" data-path="probability.html"><a href="probability.html#empirical-frequency"><i class="fa fa-check"></i><b>6.2.2</b> Empirical frequency</a></li>
<li class="chapter" data-level="6.2.3" data-path="probability.html"><a href="probability.html#classical-probability"><i class="fa fa-check"></i><b>6.2.3</b> Classical probability</a></li>
<li class="chapter" data-level="6.2.4" data-path="probability.html"><a href="probability.html#solving-de-mérés-problem"><i class="fa fa-check"></i><b>6.2.4</b> Solving de Méré’s problem</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="probability.html"><a href="probability.html#probability-distributions"><i class="fa fa-check"></i><b>6.3</b> Probability distributions</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="probability.html"><a href="probability.html#cumulative-probability-distributions"><i class="fa fa-check"></i><b>6.3.1</b> Cumulative probability distributions</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="probability.html"><a href="probability.html#conditional-probability"><i class="fa fa-check"></i><b>6.4</b> Conditional probability</a></li>
<li class="chapter" data-level="6.5" data-path="probability.html"><a href="probability.html#computing-conditional-probabilities-from-data"><i class="fa fa-check"></i><b>6.5</b> Computing conditional probabilities from data</a></li>
<li class="chapter" data-level="6.6" data-path="probability.html"><a href="probability.html#independence"><i class="fa fa-check"></i><b>6.6</b> Independence</a></li>
<li class="chapter" data-level="6.7" data-path="probability.html"><a href="probability.html#bayestheorem"><i class="fa fa-check"></i><b>6.7</b> Reversing a conditional probability: Bayes’ rule</a></li>
<li class="chapter" data-level="6.8" data-path="probability.html"><a href="probability.html#learning-from-data-1"><i class="fa fa-check"></i><b>6.8</b> Learning from data</a></li>
<li class="chapter" data-level="6.9" data-path="probability.html"><a href="probability.html#odds-and-odds-ratios"><i class="fa fa-check"></i><b>6.9</b> Odds and odds ratios</a></li>
<li class="chapter" data-level="6.10" data-path="probability.html"><a href="probability.html#what-do-probabilities-mean"><i class="fa fa-check"></i><b>6.10</b> What do probabilities mean?</a></li>
<li class="chapter" data-level="6.11" data-path="probability.html"><a href="probability.html#learning-objectives-5"><i class="fa fa-check"></i><b>6.11</b> Learning objectives</a></li>
<li class="chapter" data-level="6.12" data-path="probability.html"><a href="probability.html#suggested-readings-3"><i class="fa fa-check"></i><b>6.12</b> Suggested readings</a></li>
<li class="chapter" data-level="6.13" data-path="probability.html"><a href="probability.html#appendix-2"><i class="fa fa-check"></i><b>6.13</b> Appendix</a>
<ul>
<li class="chapter" data-level="6.13.1" data-path="probability.html"><a href="probability.html#derivation-of-bayes-rule"><i class="fa fa-check"></i><b>6.13.1</b> Derivation of Bayes’ rule</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="sampling.html"><a href="sampling.html"><i class="fa fa-check"></i><b>7</b> Sampling</a>
<ul>
<li class="chapter" data-level="7.1" data-path="sampling.html"><a href="sampling.html#how-do-we-sample"><i class="fa fa-check"></i><b>7.1</b> How do we sample?</a></li>
<li class="chapter" data-level="7.2" data-path="sampling.html"><a href="sampling.html#samplingerror"><i class="fa fa-check"></i><b>7.2</b> Sampling error</a></li>
<li class="chapter" data-level="7.3" data-path="sampling.html"><a href="sampling.html#standard-error-of-the-mean"><i class="fa fa-check"></i><b>7.3</b> Standard error of the mean</a></li>
<li class="chapter" data-level="7.4" data-path="sampling.html"><a href="sampling.html#the-central-limit-theorem"><i class="fa fa-check"></i><b>7.4</b> The Central Limit Theorem</a></li>
<li class="chapter" data-level="7.5" data-path="sampling.html"><a href="sampling.html#learning-objectives-6"><i class="fa fa-check"></i><b>7.5</b> Learning objectives</a></li>
<li class="chapter" data-level="7.6" data-path="sampling.html"><a href="sampling.html#suggested-readings-4"><i class="fa fa-check"></i><b>7.6</b> Suggested readings</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="resampling-and-simulation.html"><a href="resampling-and-simulation.html"><i class="fa fa-check"></i><b>8</b> Resampling and simulation</a>
<ul>
<li class="chapter" data-level="8.1" data-path="resampling-and-simulation.html"><a href="resampling-and-simulation.html#monte-carlo-simulation"><i class="fa fa-check"></i><b>8.1</b> Monte Carlo simulation</a></li>
<li class="chapter" data-level="8.2" data-path="resampling-and-simulation.html"><a href="resampling-and-simulation.html#randomness-in-statistics"><i class="fa fa-check"></i><b>8.2</b> Randomness in statistics</a></li>
<li class="chapter" data-level="8.3" data-path="resampling-and-simulation.html"><a href="resampling-and-simulation.html#generating-random-numbers"><i class="fa fa-check"></i><b>8.3</b> Generating random numbers</a></li>
<li class="chapter" data-level="8.4" data-path="resampling-and-simulation.html"><a href="resampling-and-simulation.html#using-monte-carlo-simulation"><i class="fa fa-check"></i><b>8.4</b> Using Monte Carlo simulation</a></li>
<li class="chapter" data-level="8.5" data-path="resampling-and-simulation.html"><a href="resampling-and-simulation.html#using-simulation-for-statistics-the-bootstrap"><i class="fa fa-check"></i><b>8.5</b> Using simulation for statistics: The bootstrap</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="resampling-and-simulation.html"><a href="resampling-and-simulation.html#computing-the-bootstrap"><i class="fa fa-check"></i><b>8.5.1</b> Computing the bootstrap</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="resampling-and-simulation.html"><a href="resampling-and-simulation.html#learning-objectives-7"><i class="fa fa-check"></i><b>8.6</b> Learning objectives</a></li>
<li class="chapter" data-level="8.7" data-path="resampling-and-simulation.html"><a href="resampling-and-simulation.html#suggested-readings-5"><i class="fa fa-check"></i><b>8.7</b> Suggested readings</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>9</b> Hypothesis testing</a>
<ul>
<li class="chapter" data-level="9.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#null-hypothesis-statistical-testing-nhst"><i class="fa fa-check"></i><b>9.1</b> Null Hypothesis Statistical Testing (NHST)</a></li>
<li class="chapter" data-level="9.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#null-hypothesis-statistical-testing-an-example"><i class="fa fa-check"></i><b>9.2</b> Null hypothesis statistical testing: An example</a></li>
<li class="chapter" data-level="9.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#the-process-of-null-hypothesis-testing"><i class="fa fa-check"></i><b>9.3</b> The process of null hypothesis testing</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#step-1-formulate-a-hypothesis-of-interest"><i class="fa fa-check"></i><b>9.3.1</b> Step 1: Formulate a hypothesis of interest</a></li>
<li class="chapter" data-level="9.3.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#step-2-specify-the-null-and-alternative-hypotheses"><i class="fa fa-check"></i><b>9.3.2</b> Step 2: Specify the null and alternative hypotheses</a></li>
<li class="chapter" data-level="9.3.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#step-3-collect-some-data"><i class="fa fa-check"></i><b>9.3.3</b> Step 3: Collect some data</a></li>
<li class="chapter" data-level="9.3.4" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#step-4-fit-a-model-to-the-data-and-compute-a-test-statistic"><i class="fa fa-check"></i><b>9.3.4</b> Step 4: Fit a model to the data and compute a test statistic</a></li>
<li class="chapter" data-level="9.3.5" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#step-5-determine-the-probability-of-the-observed-result-under-the-null-hypothesis"><i class="fa fa-check"></i><b>9.3.5</b> Step 5: Determine the probability of the observed result under the null hypothesis</a></li>
<li class="chapter" data-level="9.3.6" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#step-6-assess-the-statistical-significance-of-the-result"><i class="fa fa-check"></i><b>9.3.6</b> Step 6: Assess the “statistical significance” of the result</a></li>
<li class="chapter" data-level="9.3.7" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#what-does-a-significant-result-mean"><i class="fa fa-check"></i><b>9.3.7</b> What does a significant result mean?</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#nhst-in-a-modern-context-multiple-testing"><i class="fa fa-check"></i><b>9.4</b> NHST in a modern context: Multiple testing</a></li>
<li class="chapter" data-level="9.5" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#learning-objectives-8"><i class="fa fa-check"></i><b>9.5</b> Learning objectives</a></li>
<li class="chapter" data-level="9.6" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#suggested-readings-6"><i class="fa fa-check"></i><b>9.6</b> Suggested readings</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="ci-effect-size-power.html"><a href="ci-effect-size-power.html"><i class="fa fa-check"></i><b>10</b> Quantifying effects and designing studies</a>
<ul>
<li class="chapter" data-level="10.1" data-path="ci-effect-size-power.html"><a href="ci-effect-size-power.html#confidence-intervals"><i class="fa fa-check"></i><b>10.1</b> Confidence intervals</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="ci-effect-size-power.html"><a href="ci-effect-size-power.html#confidence-intervals-using-the-normal-distribution"><i class="fa fa-check"></i><b>10.1.1</b> Confidence intervals using the normal distribution</a></li>
<li class="chapter" data-level="10.1.2" data-path="ci-effect-size-power.html"><a href="ci-effect-size-power.html#confidence-intervals-using-the-t-distribution"><i class="fa fa-check"></i><b>10.1.2</b> Confidence intervals using the t distribution</a></li>
<li class="chapter" data-level="10.1.3" data-path="ci-effect-size-power.html"><a href="ci-effect-size-power.html#confidence-intervals-and-sample-size"><i class="fa fa-check"></i><b>10.1.3</b> Confidence intervals and sample size</a></li>
<li class="chapter" data-level="10.1.4" data-path="ci-effect-size-power.html"><a href="ci-effect-size-power.html#computing-confidence-intervals-using-the-bootstrap"><i class="fa fa-check"></i><b>10.1.4</b> Computing confidence intervals using the bootstrap</a></li>
<li class="chapter" data-level="10.1.5" data-path="ci-effect-size-power.html"><a href="ci-effect-size-power.html#relation-of-confidence-intervals-to-hypothesis-tests"><i class="fa fa-check"></i><b>10.1.5</b> Relation of confidence intervals to hypothesis tests</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="ci-effect-size-power.html"><a href="ci-effect-size-power.html#effect-sizes"><i class="fa fa-check"></i><b>10.2</b> Effect sizes</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="ci-effect-size-power.html"><a href="ci-effect-size-power.html#cohens-d"><i class="fa fa-check"></i><b>10.2.1</b> Cohen’s D</a></li>
<li class="chapter" data-level="10.2.2" data-path="ci-effect-size-power.html"><a href="ci-effect-size-power.html#pearsons-r"><i class="fa fa-check"></i><b>10.2.2</b> Pearson’s r</a></li>
<li class="chapter" data-level="10.2.3" data-path="ci-effect-size-power.html"><a href="ci-effect-size-power.html#odds-ratio"><i class="fa fa-check"></i><b>10.2.3</b> Odds ratio</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="ci-effect-size-power.html"><a href="ci-effect-size-power.html#statistical-power"><i class="fa fa-check"></i><b>10.3</b> Statistical power</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="ci-effect-size-power.html"><a href="ci-effect-size-power.html#power-analysis"><i class="fa fa-check"></i><b>10.3.1</b> Power analysis</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="ci-effect-size-power.html"><a href="ci-effect-size-power.html#learning-objectives-9"><i class="fa fa-check"></i><b>10.4</b> Learning objectives</a></li>
<li class="chapter" data-level="10.5" data-path="ci-effect-size-power.html"><a href="ci-effect-size-power.html#suggested-readings-7"><i class="fa fa-check"></i><b>10.5</b> Suggested readings</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html"><i class="fa fa-check"></i><b>11</b> Bayesian statistics</a>
<ul>
<li class="chapter" data-level="11.1" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#generative-models"><i class="fa fa-check"></i><b>11.1</b> Generative models</a></li>
<li class="chapter" data-level="11.2" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#bayes-theorem-and-inverse-inference"><i class="fa fa-check"></i><b>11.2</b> Bayes’ theorem and inverse inference</a></li>
<li class="chapter" data-level="11.3" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#doing-bayesian-estimation"><i class="fa fa-check"></i><b>11.3</b> Doing Bayesian estimation</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#specifying-the-prior"><i class="fa fa-check"></i><b>11.3.1</b> Specifying the prior</a></li>
<li class="chapter" data-level="11.3.2" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#collect-some-data"><i class="fa fa-check"></i><b>11.3.2</b> Collect some data</a></li>
<li class="chapter" data-level="11.3.3" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#computing-the-likelihood"><i class="fa fa-check"></i><b>11.3.3</b> Computing the likelihood</a></li>
<li class="chapter" data-level="11.3.4" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#computing-the-marginal-likelihood"><i class="fa fa-check"></i><b>11.3.4</b> Computing the marginal likelihood</a></li>
<li class="chapter" data-level="11.3.5" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#computing-the-posterior"><i class="fa fa-check"></i><b>11.3.5</b> Computing the posterior</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#estimating-posterior-distributions"><i class="fa fa-check"></i><b>11.4</b> Estimating posterior distributions</a>
<ul>
<li class="chapter" data-level="11.4.1" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#specifying-the-prior-1"><i class="fa fa-check"></i><b>11.4.1</b> Specifying the prior</a></li>
<li class="chapter" data-level="11.4.2" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#collect-some-data-1"><i class="fa fa-check"></i><b>11.4.2</b> Collect some data</a></li>
<li class="chapter" data-level="11.4.3" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#computing-the-likelihood-1"><i class="fa fa-check"></i><b>11.4.3</b> Computing the likelihood</a></li>
<li class="chapter" data-level="11.4.4" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#computing-the-marginal-likelihood-1"><i class="fa fa-check"></i><b>11.4.4</b> Computing the marginal likelihood</a></li>
<li class="chapter" data-level="11.4.5" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#computing-the-posterior-1"><i class="fa fa-check"></i><b>11.4.5</b> Computing the posterior</a></li>
<li class="chapter" data-level="11.4.6" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#maximum-a-posteriori-map-estimation"><i class="fa fa-check"></i><b>11.4.6</b> Maximum a posteriori (MAP) estimation</a></li>
<li class="chapter" data-level="11.4.7" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#credible-intervals"><i class="fa fa-check"></i><b>11.4.7</b> Credible intervals</a></li>
<li class="chapter" data-level="11.4.8" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#effects-of-different-priors"><i class="fa fa-check"></i><b>11.4.8</b> Effects of different priors</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#choosing-a-prior"><i class="fa fa-check"></i><b>11.5</b> Choosing a prior</a></li>
<li class="chapter" data-level="11.6" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#bayesian-hypothesis-testing"><i class="fa fa-check"></i><b>11.6</b> Bayesian hypothesis testing</a>
<ul>
<li class="chapter" data-level="11.6.1" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#Bayes-factors"><i class="fa fa-check"></i><b>11.6.1</b> Bayes factors</a></li>
<li class="chapter" data-level="11.6.2" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#bayes-factors-for-statistical-hypotheses"><i class="fa fa-check"></i><b>11.6.2</b> Bayes factors for statistical hypotheses</a></li>
<li class="chapter" data-level="11.6.3" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#assessing-evidence-for-the-null-hypothesis"><i class="fa fa-check"></i><b>11.6.3</b> Assessing evidence for the null hypothesis</a></li>
</ul></li>
<li class="chapter" data-level="11.7" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#learning-objectives-10"><i class="fa fa-check"></i><b>11.7</b> Learning objectives</a></li>
<li class="chapter" data-level="11.8" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#suggested-readings-8"><i class="fa fa-check"></i><b>11.8</b> Suggested readings</a></li>
<li class="chapter" data-level="11.9" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#appendix-3"><i class="fa fa-check"></i><b>11.9</b> Appendix:</a>
<ul>
<li class="chapter" data-level="11.9.1" data-path="bayesian-statistics.html"><a href="bayesian-statistics.html#rejection-sampling"><i class="fa fa-check"></i><b>11.9.1</b> Rejection sampling</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="modeling-categorical-relationships.html"><a href="modeling-categorical-relationships.html"><i class="fa fa-check"></i><b>12</b> Modeling categorical relationships</a>
<ul>
<li class="chapter" data-level="12.1" data-path="modeling-categorical-relationships.html"><a href="modeling-categorical-relationships.html#example-candy-colors"><i class="fa fa-check"></i><b>12.1</b> Example: Candy colors</a></li>
<li class="chapter" data-level="12.2" data-path="modeling-categorical-relationships.html"><a href="modeling-categorical-relationships.html#chi-squared-test"><i class="fa fa-check"></i><b>12.2</b> Pearson’s chi-squared test</a></li>
<li class="chapter" data-level="12.3" data-path="modeling-categorical-relationships.html"><a href="modeling-categorical-relationships.html#two-way-test"><i class="fa fa-check"></i><b>12.3</b> Contingency tables and the two-way test</a></li>
<li class="chapter" data-level="12.4" data-path="modeling-categorical-relationships.html"><a href="modeling-categorical-relationships.html#standardized-residuals"><i class="fa fa-check"></i><b>12.4</b> Standardized residuals</a></li>
<li class="chapter" data-level="12.5" data-path="modeling-categorical-relationships.html"><a href="modeling-categorical-relationships.html#odds-ratios"><i class="fa fa-check"></i><b>12.5</b> Odds ratios</a></li>
<li class="chapter" data-level="12.6" data-path="modeling-categorical-relationships.html"><a href="modeling-categorical-relationships.html#bayes-factor"><i class="fa fa-check"></i><b>12.6</b> Bayes factor</a></li>
<li class="chapter" data-level="12.7" data-path="modeling-categorical-relationships.html"><a href="modeling-categorical-relationships.html#categorical-analysis-beyond-the-2-x-2-table"><i class="fa fa-check"></i><b>12.7</b> Categorical analysis beyond the 2 X 2 table</a></li>
<li class="chapter" data-level="12.8" data-path="modeling-categorical-relationships.html"><a href="modeling-categorical-relationships.html#beware-of-simpsons-paradox"><i class="fa fa-check"></i><b>12.8</b> Beware of Simpson’s paradox</a></li>
<li class="chapter" data-level="12.9" data-path="modeling-categorical-relationships.html"><a href="modeling-categorical-relationships.html#learning-objectives-11"><i class="fa fa-check"></i><b>12.9</b> Learning objectives</a></li>
<li class="chapter" data-level="12.10" data-path="modeling-categorical-relationships.html"><a href="modeling-categorical-relationships.html#additional-readings"><i class="fa fa-check"></i><b>12.10</b> Additional readings</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="modeling-continuous-relationships.html"><a href="modeling-continuous-relationships.html"><i class="fa fa-check"></i><b>13</b> Modeling continuous relationships</a>
<ul>
<li class="chapter" data-level="13.1" data-path="modeling-continuous-relationships.html"><a href="modeling-continuous-relationships.html#an-example-hate-crimes-and-income-inequality"><i class="fa fa-check"></i><b>13.1</b> An example: Hate crimes and income inequality</a></li>
<li class="chapter" data-level="13.2" data-path="modeling-continuous-relationships.html"><a href="modeling-continuous-relationships.html#is-income-inequality-related-to-hate-crimes"><i class="fa fa-check"></i><b>13.2</b> Is income inequality related to hate crimes?</a></li>
<li class="chapter" data-level="13.3" data-path="modeling-continuous-relationships.html"><a href="modeling-continuous-relationships.html#covariance-and-correlation"><i class="fa fa-check"></i><b>13.3</b> Covariance and correlation</a>
<ul>
<li class="chapter" data-level="13.3.1" data-path="modeling-continuous-relationships.html"><a href="modeling-continuous-relationships.html#hypothesis-testing-for-correlations"><i class="fa fa-check"></i><b>13.3.1</b> Hypothesis testing for correlations</a></li>
<li class="chapter" data-level="13.3.2" data-path="modeling-continuous-relationships.html"><a href="modeling-continuous-relationships.html#robust-correlations"><i class="fa fa-check"></i><b>13.3.2</b> Robust correlations</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="modeling-continuous-relationships.html"><a href="modeling-continuous-relationships.html#correlation-and-causation"><i class="fa fa-check"></i><b>13.4</b> Correlation and causation</a>
<ul>
<li class="chapter" data-level="13.4.1" data-path="modeling-continuous-relationships.html"><a href="modeling-continuous-relationships.html#causal-graphs"><i class="fa fa-check"></i><b>13.4.1</b> Causal graphs</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="modeling-continuous-relationships.html"><a href="modeling-continuous-relationships.html#learning-objectives-12"><i class="fa fa-check"></i><b>13.5</b> Learning objectives</a></li>
<li class="chapter" data-level="13.6" data-path="modeling-continuous-relationships.html"><a href="modeling-continuous-relationships.html#suggested-readings-9"><i class="fa fa-check"></i><b>13.6</b> Suggested readings</a></li>
<li class="chapter" data-level="13.7" data-path="modeling-continuous-relationships.html"><a href="modeling-continuous-relationships.html#appendix-4"><i class="fa fa-check"></i><b>13.7</b> Appendix:</a>
<ul>
<li class="chapter" data-level="13.7.1" data-path="modeling-continuous-relationships.html"><a href="modeling-continuous-relationships.html#quantifying-inequality-the-gini-index"><i class="fa fa-check"></i><b>13.7.1</b> Quantifying inequality: The Gini index</a></li>
<li class="chapter" data-level="13.7.2" data-path="modeling-continuous-relationships.html"><a href="modeling-continuous-relationships.html#bayesian-correlation-analysis"><i class="fa fa-check"></i><b>13.7.2</b> Bayesian correlation analysis</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="the-general-linear-model.html"><a href="the-general-linear-model.html"><i class="fa fa-check"></i><b>14</b> The General Linear Model</a>
<ul>
<li class="chapter" data-level="14.1" data-path="the-general-linear-model.html"><a href="the-general-linear-model.html#linear-regression"><i class="fa fa-check"></i><b>14.1</b> Linear regression</a>
<ul>
<li class="chapter" data-level="14.1.1" data-path="the-general-linear-model.html"><a href="the-general-linear-model.html#regression-to-the-mean"><i class="fa fa-check"></i><b>14.1.1</b> Regression to the mean</a></li>
<li class="chapter" data-level="14.1.2" data-path="the-general-linear-model.html"><a href="the-general-linear-model.html#the-relation-between-correlation-and-regression"><i class="fa fa-check"></i><b>14.1.2</b> The relation between correlation and regression</a></li>
<li class="chapter" data-level="14.1.3" data-path="the-general-linear-model.html"><a href="the-general-linear-model.html#standard-errors-for-regression-models"><i class="fa fa-check"></i><b>14.1.3</b> Standard errors for regression models</a></li>
<li class="chapter" data-level="14.1.4" data-path="the-general-linear-model.html"><a href="the-general-linear-model.html#statistical-tests-for-regression-parameters"><i class="fa fa-check"></i><b>14.1.4</b> Statistical tests for regression parameters</a></li>
<li class="chapter" data-level="14.1.5" data-path="the-general-linear-model.html"><a href="the-general-linear-model.html#quantifying-goodness-of-fit-of-the-model"><i class="fa fa-check"></i><b>14.1.5</b> Quantifying goodness of fit of the model</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="the-general-linear-model.html"><a href="the-general-linear-model.html#fitting-more-complex-models"><i class="fa fa-check"></i><b>14.2</b> Fitting more complex models</a></li>
<li class="chapter" data-level="14.3" data-path="the-general-linear-model.html"><a href="the-general-linear-model.html#interactions-between-variables"><i class="fa fa-check"></i><b>14.3</b> Interactions between variables</a></li>
<li class="chapter" data-level="14.4" data-path="the-general-linear-model.html"><a href="the-general-linear-model.html#beyond-linear-predictors-and-outcomes"><i class="fa fa-check"></i><b>14.4</b> Beyond linear predictors and outcomes</a></li>
<li class="chapter" data-level="14.5" data-path="the-general-linear-model.html"><a href="the-general-linear-model.html#model-criticism"><i class="fa fa-check"></i><b>14.5</b> Criticizing our model and checking assumptions</a></li>
<li class="chapter" data-level="14.6" data-path="the-general-linear-model.html"><a href="the-general-linear-model.html#what-does-predict-really-mean"><i class="fa fa-check"></i><b>14.6</b> What does “predict” really mean?</a>
<ul>
<li class="chapter" data-level="14.6.1" data-path="the-general-linear-model.html"><a href="the-general-linear-model.html#cross-validation"><i class="fa fa-check"></i><b>14.6.1</b> Cross-validation</a></li>
</ul></li>
<li class="chapter" data-level="14.7" data-path="the-general-linear-model.html"><a href="the-general-linear-model.html#learning-objectives-13"><i class="fa fa-check"></i><b>14.7</b> Learning objectives</a></li>
<li class="chapter" data-level="14.8" data-path="the-general-linear-model.html"><a href="the-general-linear-model.html#suggested-readings-10"><i class="fa fa-check"></i><b>14.8</b> Suggested readings</a></li>
<li class="chapter" data-level="14.9" data-path="the-general-linear-model.html"><a href="the-general-linear-model.html#appendix-5"><i class="fa fa-check"></i><b>14.9</b> Appendix</a>
<ul>
<li class="chapter" data-level="14.9.1" data-path="the-general-linear-model.html"><a href="the-general-linear-model.html#estimating-linear-regression-parameters"><i class="fa fa-check"></i><b>14.9.1</b> Estimating linear regression parameters</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="comparing-means.html"><a href="comparing-means.html"><i class="fa fa-check"></i><b>15</b> Comparing means</a>
<ul>
<li class="chapter" data-level="15.1" data-path="comparing-means.html"><a href="comparing-means.html#single-mean"><i class="fa fa-check"></i><b>15.1</b> Testing the value of a single mean</a></li>
<li class="chapter" data-level="15.2" data-path="comparing-means.html"><a href="comparing-means.html#comparing-two-means"><i class="fa fa-check"></i><b>15.2</b> Comparing two means</a></li>
<li class="chapter" data-level="15.3" data-path="comparing-means.html"><a href="comparing-means.html#ttest-linear-model"><i class="fa fa-check"></i><b>15.3</b> The t-test as a linear model</a>
<ul>
<li class="chapter" data-level="15.3.1" data-path="comparing-means.html"><a href="comparing-means.html#effect-sizes-for-comparing-two-means"><i class="fa fa-check"></i><b>15.3.1</b> Effect sizes for comparing two means</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="comparing-means.html"><a href="comparing-means.html#bayes-factor-for-mean-differences"><i class="fa fa-check"></i><b>15.4</b> Bayes factor for mean differences</a></li>
<li class="chapter" data-level="15.5" data-path="comparing-means.html"><a href="comparing-means.html#paired-ttests"><i class="fa fa-check"></i><b>15.5</b> Comparing paired observations</a>
<ul>
<li class="chapter" data-level="15.5.1" data-path="comparing-means.html"><a href="comparing-means.html#sign-test"><i class="fa fa-check"></i><b>15.5.1</b> Sign test</a></li>
<li class="chapter" data-level="15.5.2" data-path="comparing-means.html"><a href="comparing-means.html#paired-t-test"><i class="fa fa-check"></i><b>15.5.2</b> Paired t-test</a></li>
</ul></li>
<li class="chapter" data-level="15.6" data-path="comparing-means.html"><a href="comparing-means.html#comparing-more-than-two-means"><i class="fa fa-check"></i><b>15.6</b> Comparing more than two means</a>
<ul>
<li class="chapter" data-level="15.6.1" data-path="comparing-means.html"><a href="comparing-means.html#ANOVA"><i class="fa fa-check"></i><b>15.6.1</b> Analysis of variance</a></li>
</ul></li>
<li class="chapter" data-level="15.7" data-path="comparing-means.html"><a href="comparing-means.html#learning-objectives-14"><i class="fa fa-check"></i><b>15.7</b> Learning objectives</a></li>
<li class="chapter" data-level="15.8" data-path="comparing-means.html"><a href="comparing-means.html#appendix-6"><i class="fa fa-check"></i><b>15.8</b> Appendix</a>
<ul>
<li class="chapter" data-level="15.8.1" data-path="comparing-means.html"><a href="comparing-means.html#the-paired-t-test-as-a-linear-model"><i class="fa fa-check"></i><b>15.8.1</b> The paired t-test as a linear model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="multivariate.html"><a href="multivariate.html"><i class="fa fa-check"></i><b>16</b> Multivariate statistics</a>
<ul>
<li class="chapter" data-level="16.1" data-path="multivariate.html"><a href="multivariate.html#multivariate-data-an-example"><i class="fa fa-check"></i><b>16.1</b> Multivariate data: An example</a></li>
<li class="chapter" data-level="16.2" data-path="multivariate.html"><a href="multivariate.html#visualizing-multivariate-data"><i class="fa fa-check"></i><b>16.2</b> Visualizing multivariate data</a>
<ul>
<li class="chapter" data-level="16.2.1" data-path="multivariate.html"><a href="multivariate.html#scatterplot-of-matrices"><i class="fa fa-check"></i><b>16.2.1</b> Scatterplot of matrices</a></li>
<li class="chapter" data-level="16.2.2" data-path="multivariate.html"><a href="multivariate.html#heatmap"><i class="fa fa-check"></i><b>16.2.2</b> Heatmap</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="multivariate.html"><a href="multivariate.html#clustering"><i class="fa fa-check"></i><b>16.3</b> Clustering</a>
<ul>
<li class="chapter" data-level="16.3.1" data-path="multivariate.html"><a href="multivariate.html#k-means-clustering"><i class="fa fa-check"></i><b>16.3.1</b> K-means clustering</a></li>
<li class="chapter" data-level="16.3.2" data-path="multivariate.html"><a href="multivariate.html#hierarchical-clustering"><i class="fa fa-check"></i><b>16.3.2</b> Hierarchical clustering</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="multivariate.html"><a href="multivariate.html#dimensionality-reduction"><i class="fa fa-check"></i><b>16.4</b> Dimensionality reduction</a>
<ul>
<li class="chapter" data-level="16.4.1" data-path="multivariate.html"><a href="multivariate.html#principal-component-analysis"><i class="fa fa-check"></i><b>16.4.1</b> Principal component analysis</a></li>
<li class="chapter" data-level="16.4.2" data-path="multivariate.html"><a href="multivariate.html#factor-analysis"><i class="fa fa-check"></i><b>16.4.2</b> Factor analysis</a></li>
<li class="chapter" data-level="16.4.3" data-path="multivariate.html"><a href="multivariate.html#determining-the-number-of-factors"><i class="fa fa-check"></i><b>16.4.3</b> Determining the number of factors</a></li>
</ul></li>
<li class="chapter" data-level="16.5" data-path="multivariate.html"><a href="multivariate.html#learning-objectives-15"><i class="fa fa-check"></i><b>16.5</b> Learning objectives</a></li>
<li class="chapter" data-level="16.6" data-path="multivariate.html"><a href="multivariate.html#suggested-readings-11"><i class="fa fa-check"></i><b>16.6</b> Suggested readings</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="practical-example.html"><a href="practical-example.html"><i class="fa fa-check"></i><b>17</b> Practical statistical modeling</a>
<ul>
<li class="chapter" data-level="17.1" data-path="practical-example.html"><a href="practical-example.html#the-process-of-statistical-modeling"><i class="fa fa-check"></i><b>17.1</b> The process of statistical modeling</a>
<ul>
<li class="chapter" data-level="17.1.1" data-path="practical-example.html"><a href="practical-example.html#specify-your-question-of-interest"><i class="fa fa-check"></i><b>17.1.1</b> 1: Specify your question of interest</a></li>
<li class="chapter" data-level="17.1.2" data-path="practical-example.html"><a href="practical-example.html#identify-or-collect-the-appropriate-data"><i class="fa fa-check"></i><b>17.1.2</b> 2: Identify or collect the appropriate data</a></li>
<li class="chapter" data-level="17.1.3" data-path="practical-example.html"><a href="practical-example.html#prepare-the-data-for-analysis"><i class="fa fa-check"></i><b>17.1.3</b> 3: Prepare the data for analysis</a></li>
<li class="chapter" data-level="17.1.4" data-path="practical-example.html"><a href="practical-example.html#determine-the-appropriate-model"><i class="fa fa-check"></i><b>17.1.4</b> 4. Determine the appropriate model</a></li>
<li class="chapter" data-level="17.1.5" data-path="practical-example.html"><a href="practical-example.html#fit-the-model-to-the-data"><i class="fa fa-check"></i><b>17.1.5</b> 5. Fit the model to the data</a></li>
<li class="chapter" data-level="17.1.6" data-path="practical-example.html"><a href="practical-example.html#criticize-the-model-to-make-sure-it-fits-properly"><i class="fa fa-check"></i><b>17.1.6</b> 6. Criticize the model to make sure it fits properly</a></li>
<li class="chapter" data-level="17.1.7" data-path="practical-example.html"><a href="practical-example.html#test-hypothesis-and-quantify-effect-size"><i class="fa fa-check"></i><b>17.1.7</b> 7. Test hypothesis and quantify effect size</a></li>
<li class="chapter" data-level="17.1.8" data-path="practical-example.html"><a href="practical-example.html#what-about-possible-confounds"><i class="fa fa-check"></i><b>17.1.8</b> What about possible confounds?</a></li>
</ul></li>
<li class="chapter" data-level="17.2" data-path="practical-example.html"><a href="practical-example.html#getting-help"><i class="fa fa-check"></i><b>17.2</b> Getting help</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html"><i class="fa fa-check"></i><b>18</b> Doing reproducible research</a>
<ul>
<li class="chapter" data-level="18.1" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html#how-we-think-science-should-work"><i class="fa fa-check"></i><b>18.1</b> How we think science should work</a></li>
<li class="chapter" data-level="18.2" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html#how-science-sometimes-actually-works"><i class="fa fa-check"></i><b>18.2</b> How science (sometimes) actually works</a></li>
<li class="chapter" data-level="18.3" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html#the-reproducibility-crisis-in-science"><i class="fa fa-check"></i><b>18.3</b> The reproducibility crisis in science</a>
<ul>
<li class="chapter" data-level="18.3.1" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html#positive-predictive-value-and-statistical-significance"><i class="fa fa-check"></i><b>18.3.1</b> Positive predictive value and statistical significance</a></li>
<li class="chapter" data-level="18.3.2" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html#the-winners-curse"><i class="fa fa-check"></i><b>18.3.2</b> The winner’s curse</a></li>
</ul></li>
<li class="chapter" data-level="18.4" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html#questionable-research-practices"><i class="fa fa-check"></i><b>18.4</b> Questionable research practices</a>
<ul>
<li class="chapter" data-level="18.4.1" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html#esp-or-qrp"><i class="fa fa-check"></i><b>18.4.1</b> ESP or QRP?</a></li>
</ul></li>
<li class="chapter" data-level="18.5" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html#doing-reproducible-research-1"><i class="fa fa-check"></i><b>18.5</b> Doing reproducible research</a>
<ul>
<li class="chapter" data-level="18.5.1" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html#pre-registration"><i class="fa fa-check"></i><b>18.5.1</b> Pre-registration</a></li>
<li class="chapter" data-level="18.5.2" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html#reproducible-practices"><i class="fa fa-check"></i><b>18.5.2</b> Reproducible practices</a></li>
<li class="chapter" data-level="18.5.3" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html#replication"><i class="fa fa-check"></i><b>18.5.3</b> Replication</a></li>
</ul></li>
<li class="chapter" data-level="18.6" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html#doing-reproducible-data-analysis"><i class="fa fa-check"></i><b>18.6</b> Doing reproducible data analysis</a></li>
<li class="chapter" data-level="18.7" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html#conclusion-doing-better-science"><i class="fa fa-check"></i><b>18.7</b> Conclusion: Doing better science</a></li>
<li class="chapter" data-level="18.8" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html#learning-objectives-16"><i class="fa fa-check"></i><b>18.8</b> Learning objectives</a></li>
<li class="chapter" data-level="18.9" data-path="doing-reproducible-research.html"><a href="doing-reproducible-research.html#suggested-readings-12"><i class="fa fa-check"></i><b>18.9</b> Suggested Readings</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistical Thinking for the 21st Century</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="ci-effect-size-power" class="section level1 hasAnchor" number="10">
<h1><span class="header-section-number">Chapter 10</span> Quantifying effects and designing studies<a href="ci-effect-size-power.html#ci-effect-size-power" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>In the previous chapter we discussed how we can use data to test hypotheses. Those methods provided a binary answer: we either reject or fail to reject the null hypothesis. However, this kind of decision overlooks a couple of important questions. First, we would like to know how much uncertainty we have about the answer (regardless of which way it goes). In addition, sometimes we don’t have a clear null hypothesis, so we would like to see what range of estimates are consistent with the data. Second, we would like to know how large the effect actually is, since as we saw in the weight loss example in the previous chapter, a statistically significant effect is not necessarily a practically important effect.</p>
<p>In this chapter we will discuss methods to address these two questions: confidence intervals to provide a measure of our uncertainty about our estimates, and effect sizes to provide a standardized way to understand how large the effects are. We will also discuss the concept of <em>statistical power</em> which tells us how likely we are to find any true effects that actually exist.</p>
<div id="confidence-intervals" class="section level2 hasAnchor" number="10.1">
<h2><span class="header-section-number">10.1</span> Confidence intervals<a href="ci-effect-size-power.html#confidence-intervals" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>So far in the book we have focused on estimating a single value statistic. For example, let’s say we want to estimate the mean weight of adults in the NHANES dataset, so we take a sample from the dataset and estimate the mean. In this sample, the mean weight was 79.92 kilograms. We refer to this as a <em>point estimate</em> since it provides us with a single number to describe our estimate of the population parameter. However, we know from our earlier discussion of sampling error that there is some uncertainty about this estimate, which is described by the standard error. You should also remember that the standard error is determined by two components: the population standard deviation (which is the numerator), and the square root of the sample size (which is in the denominator). The population standard deviation is a generally unknown but fixed parameter that is not under our control, whereas the sample size <em>is</em> under our control. Thus, we can decrease our uncertainty about the estimate by increasing our sample size – up to the limit of the entire population size, at which point there is no uncertainty at all because we can just calculate the population parameter directly from the data of the entire population.</p>
<p>We would often like to have a way to more directly describe our uncertainty about a statistical estimate, which we can accomplish using a <em>confidence interval</em>. Most people are familiar with confidence intervals through the idea of a “margin of error” for political polls. These polls usually try to provide an answer that is accurate within +/- 3 percent. For example, when a candidate is estimated to win an election by 9 percentage points with a margin of error of 3, the percentage by which they will win is estimated to fall within 6-12 percentage points. In statistics we refer to this kind of range of values as a confidence interval, which provides a range of values for our parameter estimate that are consistent with our sample data, rather than just giving us a single estimate based on the data. The wider the confidence interval, the more uncertain we are about our parameter estimate.</p>
<p>Confidence intervals are notoriously confusing, primarily because they don’t mean what we might intuitively think they mean. If I tell you that I have computed a “95% confidence interval” for my statistic, then it would seem natural to think that we can have 95% confidence that the true parameter value falls within this interval. However, as we will see throughout the course, concepts in statistics often don’t mean what we think they should mean. In the case of confidence intervals, we can’t interpret them in this way because the population parameter has a fixed value – it either is or isn’t in the interval, so it doesn’t make sense to talk about the probability of that occurring. Jerzy Neyman, the inventor of the confidence interval, said:</p>
<blockquote>
<p>“The parameter is an unknown constant and no probability statement concerning its value may be made.”<span class="citation">(<a href="#ref-Neyman37" role="doc-biblioref">J. Neyman 1937</a>)</span></p>
</blockquote>
<p>Instead, we have to view the confidence interval procedure from the same standpoint that we viewed hypothesis testing: As a procedure that in the long run will allow us to make correct statements with a particular probability. Thus, the proper interpretation of the 95% confidence interval is that it is an interval that will contain the true population mean 95% of the time, and in fact we can confirm that using simulation, as you will see below.</p>
<p>The confidence interval for the mean is computed as:</p>
<p><span class="math display">\[
CI = \text{point estimate} \pm \text{critical value} * \text{standard error}
\]</span></p>
<p>where the critical value is determined by the sampling distribution of the estimate. The important question, then, is how we obtain our estimate for that sampling distribution.</p>
<div id="confidence-intervals-using-the-normal-distribution" class="section level3 hasAnchor" number="10.1.1">
<h3><span class="header-section-number">10.1.1</span> Confidence intervals using the normal distribution<a href="ci-effect-size-power.html#confidence-intervals-using-the-normal-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>If we know the population standard deviation, then we can use the normal distribution to compute a confidence interval. We usually don’t, but for our example of the NHANES dataset we do, since we are treating the entire dataset as the population (it’s 21.3 for weight).</p>
<p>Let’s say that we want to compute a 95% confidence interval for the mean. The critical value would then be the values of the standard normal distribution that capture 95% of the distribution; these are simply the 2.5th percentile and the 97.5th percentile of the distribution, which we can compute using our statistical software, and come out to <span class="math inline">\(\pm 1.96\)</span>. Thus, the confidence interval for the mean (<span class="math inline">\(\bar{X}\)</span>) is:</p>
<p><span class="math display">\[
CI = \bar{X} \pm 1.96*SE
\]</span></p>
<p>Using the estimated mean from our sample (79.92) and the known population standard deviation, we can compute the confidence interval of [77.28,82.56].</p>
</div>
<div id="confidence-intervals-using-the-t-distribution" class="section level3 hasAnchor" number="10.1.2">
<h3><span class="header-section-number">10.1.2</span> Confidence intervals using the t distribution<a href="ci-effect-size-power.html#confidence-intervals-using-the-t-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>As stated above, if we knew the population standard deviation, then we could use the normal distribution to compute our confidence intervals. However, in general we don’t – in which case the <em>t</em> distribution is more appropriate as a sampling distribution. Remember that the t distribution is slightly broader than the normal distribution, especially for smaller samples, which means that the confidence intervals will be slightly wider than they would if we were using the normal distribution. This incorporates the extra uncertainty that arises when we estimate parameters based on small samples.</p>
<p>We can compute the 95% confidence interval in a way similar to the normal distribution example above, but the critical value is determined by the 2.5th percentile and the 97.5th percentile of the <em>t</em> distribution with the appropriate degrees of freedom. Thus, the confidence interval for the mean (<span class="math inline">\(\bar{X}\)</span>) is:</p>
<p><span class="math display">\[
CI = \bar{X} \pm t_{crit}*SE
\]</span></p>
<p>where <span class="math inline">\(t_{crit}\)</span> is the critical t value.
For the NHANES weight example (with sample size of 250), the confidence interval would be 79.92 +/- 1.97 * 1.41 [77.15 - 82.69].</p>
<p>Remember that this doesn’t tell us anything about the probability of the true population value falling within this interval, since it is a fixed parameter (which we know is 81.77 because we have the entire population in this case) and it either does or does not fall within this specific interval (in this case, it does). Instead, it tells us that in the long run, if we compute the confidence interval using this procedure, 95% of the time that confidence interval will capture the true population parameter.</p>
<p>We can see this using the NHANES data as our population; in this case, we know the true value of the population parameter, so we can see how often the confidence interval ends up capturing that value across many different samples. Figure <a href="ci-effect-size-power.html#fig:CIcoverage">10.1</a> shows the confidence intervals for estimated mean weight computed for 100 samples from the NHANES dataset. Of these, 95 captured the true population mean weight, showing that the confidence interval procedure performs as it should.</p>
<div class="figure"><span style="display:block;" id="fig:CIcoverage"></span>
<img src="StatsThinking21_files/figure-html/CIcoverage-1.png" alt="Samples were repeatedly taken from the NHANES dataset, and the 95% confidence interval of the mean was computed for each sample.  Intervals shown in red did not capture the true population mean (shown as the dotted line)." width="768" height="50%" />
<p class="caption">
Figure 10.1: Samples were repeatedly taken from the NHANES dataset, and the 95% confidence interval of the mean was computed for each sample. Intervals shown in red did not capture the true population mean (shown as the dotted line).
</p>
</div>
</div>
<div id="confidence-intervals-and-sample-size" class="section level3 hasAnchor" number="10.1.3">
<h3><span class="header-section-number">10.1.3</span> Confidence intervals and sample size<a href="ci-effect-size-power.html#confidence-intervals-and-sample-size" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Because the standard error decreases with sample size, the confidence interval should get narrower as the sample size increases, providing progressively tighter bounds on our estimate. Figure <a href="ci-effect-size-power.html#fig:CISampSize">10.2</a> shows an example of how the confidence interval would change as a function of sample size for the weight example. From the figure it’s evident that the confidence interval becomes increasingly tighter as the sample size increases, but increasing samples provide diminishing returns, consistent with the fact that the denominator of the confidence interval term is proportional to the square root of the sample size.</p>
<div class="figure"><span style="display:block;" id="fig:CISampSize"></span>
<img src="StatsThinking21_files/figure-html/CISampSize-1.png" alt="An example of the effect of sample size on the width of the confidence interval for the mean." width="384" height="50%" />
<p class="caption">
Figure 10.2: An example of the effect of sample size on the width of the confidence interval for the mean.
</p>
</div>
</div>
<div id="computing-confidence-intervals-using-the-bootstrap" class="section level3 hasAnchor" number="10.1.4">
<h3><span class="header-section-number">10.1.4</span> Computing confidence intervals using the bootstrap<a href="ci-effect-size-power.html#computing-confidence-intervals-using-the-bootstrap" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In some cases we can’t assume normality, or we don’t know the sampling distribution of the statistic. In these cases, we can use the bootstrap (which we introduced in Chapter <a href="resampling-and-simulation.html#resampling-and-simulation">8</a>). As a reminder, the bootstrap involves repeatedly resampling the data <em>with replacement</em>, and then using the distribution of the statistic computed on those samples as a surrogate for the sampling distribution of the statistic.These are the results when we use the built-in bootstrapping function in R to compute the confidence interval for weight in our NHANES sample:</p>
<pre><code>## BOOTSTRAP CONFIDENCE INTERVAL CALCULATIONS
## Based on 1000 bootstrap replicates
## 
## CALL : 
## boot.ci(boot.out = bs, type = &quot;perc&quot;)
## 
## Intervals : 
## Level     Percentile     
## 95%   (78, 84 )  
## Calculations and Intervals on Original Scale</code></pre>
<p>These values are fairly close to the values obtained using the t distribution above, though not exactly the same.</p>
</div>
<div id="relation-of-confidence-intervals-to-hypothesis-tests" class="section level3 hasAnchor" number="10.1.5">
<h3><span class="header-section-number">10.1.5</span> Relation of confidence intervals to hypothesis tests<a href="ci-effect-size-power.html#relation-of-confidence-intervals-to-hypothesis-tests" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>There is a close relationship between confidence intervals and hypothesis tests. In particular, if the confidence interval does not include the null hypothesis, then the associated statistical test would be statistically significant. For example, if you are testing whether the mean of a sample is greater than zero with <span class="math inline">\(\alpha = 0.05\)</span>, you could simply check to see whether zero is contained within the 95% confidence interval for the mean.</p>
<p>Things get trickier if we want to compare the means of two conditions <span class="citation">(<a href="#ref-sche:gent:2001" role="doc-biblioref">Schenker and Gentleman 2001</a>)</span>. There are a couple of situations that are clear. First, if each mean is contained within the confidence interval for the other mean, then there is definitely no significant difference at the chosen confidence level. Second, if there is no overlap between the confidence intervals, then there is certainly a significant difference at the chosen level; in fact, this test is substantially <em>conservative</em>, such that the actual error rate will be lower than the chosen level. But what about the case where the confidence intervals overlap one another but don’t contain the means for the other group? In this case the answer depends on the relative variability of the two variables, and there is no general answer. However, one should in general avoid using the “eyeball test” for overlapping confidence intervals.</p>
</div>
</div>
<div id="effect-sizes" class="section level2 hasAnchor" number="10.2">
<h2><span class="header-section-number">10.2</span> Effect sizes<a href="ci-effect-size-power.html#effect-sizes" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<blockquote>
<p>“Statistical significance is the least interesting thing about the results. You should describe the results in terms of measures of magnitude – not just, does a treatment affect people, but how much does it affect them.” Gene Glass, quoted in <span class="citation">(<a href="#ref-Sullivan:2012ta" role="doc-biblioref">Sullivan and Feinn 2012</a>)</span></p>
</blockquote>
<p>In the previous chapter, we discussed the idea that statistical significance may not necessarily reflect practical significance. In order to discuss practical significance, we need a standard way to describe the size of an effect in terms of the actual data, which we refer to as an <em>effect size</em>. In this section we will introduce the concept and discuss various ways that effect sizes can be calculated.</p>
<p>An effect size is a standardized measurement that compares the size of some statistical effect to a reference quantity, such as the variability of the statistic. In some fields of science and engineering, this idea is referred to as a “signal to noise ratio”. There are many different ways that the effect size can be quantified, which depend on the nature of the data.</p>
<div id="cohens-d" class="section level3 hasAnchor" number="10.2.1">
<h3><span class="header-section-number">10.2.1</span> Cohen’s D<a href="ci-effect-size-power.html#cohens-d" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>One of the most common measures of effect size is known as <em>Cohen’s d</em>, named after the statistician Jacob Cohen (who is most famous for his 1994 paper titled “The Earth Is Round (p &lt; .05)”). It is used to quantify the difference between two means, in terms of their standard deviation:</p>
<p><span class="math display">\[
d = \frac{\bar{X}_1 - \bar{X}_2}{s}
\]</span></p>
<p>where <span class="math inline">\(\bar{X}_1\)</span> and <span class="math inline">\(\bar{X}_2\)</span> are the means of the two groups, and <span class="math inline">\(s\)</span> is the pooled standard deviation (which is a combination of the standard deviations for the two samples, weighted by their sample sizes):</p>
<p><span class="math display">\[
s = \sqrt{\frac{(n_1 - 1)s^2_1 + (n_2 - 1)s^2_2 }{n_1 +n_2 -2}}
\]</span>
where <span class="math inline">\(n_1\)</span> and <span class="math inline">\(n_2\)</span> are the sample sizes and <span class="math inline">\(s^2_1\)</span> and <span class="math inline">\(s^2_2\)</span> are the standard deviations for the two groups respectively. Note that this is very similar in spirit to the t statistic — the main difference is that the denominator in the t statistic is based on the standard error of the mean, whereas the denominator in Cohen’s D is based on the standard deviation of the data. This means that while the t statistic will grow as the sample size gets larger, the value of Cohen’s D will remain the same.</p>
<table>
<caption><span id="tab:dInterp">Table 10.1: </span>Interpetation of Cohen’s D</caption>
<thead>
<tr class="header">
<th align="left">D</th>
<th align="left">Interpretation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">0.0 - 0.2</td>
<td align="left">neglibible</td>
</tr>
<tr class="even">
<td align="left">0.2 - 0.5</td>
<td align="left">small</td>
</tr>
<tr class="odd">
<td align="left">0.5 - 0.8</td>
<td align="left">medium</td>
</tr>
<tr class="even">
<td align="left">0.8 -</td>
<td align="left">large</td>
</tr>
</tbody>
</table>
<p>There is a commonly used scale for interpreting the size of an effect in terms of Cohen’s d, shown in Table <a href="ci-effect-size-power.html#tab:dInterp">10.1</a>. It can be useful to look at some commonly understood effects to help understand these interpretations. For example, the effect size for gender differences in adult height (d = 2.05) is very large by reference to our table above. We can also see this by looking at the distributions of male and female heights in a sample from the NHANES dataset. Figure <a href="ci-effect-size-power.html#fig:genderHist">10.3</a> shows that the two distributions are quite well separated, though still overlapping, highlighting the fact that even when there is a very large effect size for the difference between two groups, there will be individuals from each group that are more like the other group.</p>
<div class="figure"><span style="display:block;" id="fig:genderHist"></span>
<img src="StatsThinking21_files/figure-html/genderHist-1.png" alt="Smoothed histogram plots for male and female heights in the NHANES dataset, showing clearly distinct but also clearly overlapping distributions." width="384" height="50%" />
<p class="caption">
Figure 10.3: Smoothed histogram plots for male and female heights in the NHANES dataset, showing clearly distinct but also clearly overlapping distributions.
</p>
</div>
<p>It is also worth noting that we rarely encounter effects of this magnitude in science, in part because they are such obvious effects that we don’t need scientific research to find them. As we will see in Chapter <a href="doing-reproducible-research.html#doing-reproducible-research">18</a> on reproducibility, very large reported effects in scientific research often reflect the use of questionable research practices rather than truly huge effects in nature. It is also worth noting that even for such a huge effect, the two distributions still overlap - there will be some females who are taller than the average male, and vice versa. For most interesting scientific effects, the degree of overlap will be much greater, so we shouldn’t immediately jump to strong conclusions about individuals from different populations based on even a large effect size.</p>
</div>
<div id="pearsons-r" class="section level3 hasAnchor" number="10.2.2">
<h3><span class="header-section-number">10.2.2</span> Pearson’s r<a href="ci-effect-size-power.html#pearsons-r" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Pearson’s <em>r</em>, also known as the <em>correlation coefficient</em>, is a measure of the strength of the linear relationship between two continuous variables. We will discuss correlation in much more detail in Chapter <a href="modeling-continuous-relationships.html#modeling-continuous-relationships">13</a>, so we will save the details for that chapter; here, we simply introduce <em>r</em> as a way to quantify the relation between two variables.</p>
<p><em>r</em> is a measure that varies from -1 to 1, where a value of 1 represents a perfect positive relationship between the variables, 0 represents no relationship, and -1 represents a perfect negative relationship. Figure <a href="ci-effect-size-power.html#fig:corrFig">10.4</a> shows examples of various levels of correlation using randomly generated data.</p>
<div class="figure"><span style="display:block;" id="fig:corrFig"></span>
<img src="StatsThinking21_files/figure-html/corrFig-1.png" alt="Examples of various levels of Pearson's r." width="864" height="50%" />
<p class="caption">
Figure 10.4: Examples of various levels of Pearson’s r.
</p>
</div>
</div>
<div id="odds-ratio" class="section level3 hasAnchor" number="10.2.3">
<h3><span class="header-section-number">10.2.3</span> Odds ratio<a href="ci-effect-size-power.html#odds-ratio" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In our earlier discussion of probability we discussed the concept of odds – that is, the relative likelihood of some event happening versus not happening:</p>
<p><span class="math display">\[
odds\ of\ A = \frac{P(A)}{P(\neg A)}
\]</span></p>
<p>We also discussed the <em>odds ratio</em>, which is simply the ratio of two odds. The odds ratio is a useful way to describe effect sizes for binary variables.</p>
<p>For example, let’s take the case of smoking and lung cancer. A study published in the International Journal of Cancer in 2012 <span class="citation">(<a href="#ref-pesc:kend:gust:2012" role="doc-biblioref">Pesch et al. 2012</a>)</span> combined data regarding the occurrence of lung cancer in smokers and individuals who have never smoked across a number of different studies. Note that these data come from case-control studies, which means that participants in the studies were recruited because they either did or did not have cancer; their smoking status was then examined. These numbers (shown in Table <a href="ci-effect-size-power.html#tab:smokingData">10.2</a>) thus do not represent the prevalence of cancer amongst smokers in the general population – but they can tell us about the relationship between cancer and smoking.</p>
<table>
<caption><span id="tab:smokingData">Table 10.2: </span>Lung cancer occurrence separately for current smokers and those who have never smoked</caption>
<thead>
<tr class="header">
<th align="left">Status</th>
<th align="right">NeverSmoked</th>
<th align="right">CurrentSmoker</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">No Cancer</td>
<td align="right">2883</td>
<td align="right">3829</td>
</tr>
<tr class="even">
<td align="left">Cancer</td>
<td align="right">220</td>
<td align="right">6784</td>
</tr>
</tbody>
</table>
<p>We can convert these numbers to odds ratios for each of the groups. The odds of a non-smoker having lung cancer are 0.08 whereas the odds of a current smoker having lung cancer are 1.77. The ratio of these odds tells us about the relative likelihood of cancer between the two groups: The odds ratio of 23.22 tells us that the odds of lung cancer in smokers are roughly 23 times higher than never-smokers.</p>
</div>
</div>
<div id="statistical-power" class="section level2 hasAnchor" number="10.3">
<h2><span class="header-section-number">10.3</span> Statistical power<a href="ci-effect-size-power.html#statistical-power" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Remember from the previous chapter that under the Neyman-Pearson hypothesis testing approach, we have to specify our level of tolerance for two kinds of errors: False positives (which they called <em>Type I error</em>) and false negatives (which they called <em>Type II error</em>). People often focus heavily on Type I error, because making a false positive claim is generally viewed as a very bad thing; for example, the now discredited claims by <span class="citation">Wakefield (<a href="#ref-wake:1999" role="doc-biblioref">1999</a>)</span> that autism was associated with vaccination led to anti-vaccine sentiment that has resulted in substantial increases in childhood diseases such as measles. Similarly, we don’t want to claim that a drug cures a disease if it really doesn’t. That’s why the tolerance for Type I errors is generally set fairly low, usually at <span class="math inline">\(\alpha = 0.05\)</span>. But what about Type II errors?</p>
<p>The concept of <em>statistical power</em> is the complement of Type II error – that is, it is the likelihood of finding a positive result given that it exists:</p>
<p><span class="math display">\[
power = 1 - \beta
\]</span></p>
<p>Another important aspect of the Neyman-Pearson model that we didn’t discuss earlier is the fact that in addition to specifying the acceptable levels of Type I and Type II errors, we also have to describe a specific alternative hypothesis – that is, what is the size of the effect that we wish to detect? Otherwise, we can’t interpret <span class="math inline">\(\beta\)</span> – the likelihood of finding a large effect is always going to be higher than finding a small effect, so <span class="math inline">\(\beta\)</span> will differ depending on the size of effect we are trying to detect.</p>
<p>There are three factors that can affect statistical power:</p>
<ul>
<li>Sample size: Larger samples provide greater statistical power</li>
<li>Effect size: A given design will always have greater power to find a large effect than a small effect (because finding large effects is easier)</li>
<li>Type I error rate: There is a relationship between Type I error and power such that (all else being equal) decreasing Type I error will also decrease power.</li>
</ul>
<p>We can see this through simulation. First let’s simulate a single experiment, in which we compare the means of two groups using a standard t-test. We will vary the size of the effect (specified in terms of Cohen’s d), the Type I error rate, and the sample size, and for each of these we will examine how the proportion of significant results (i.e. power) is affected. Figure <a href="ci-effect-size-power.html#fig:plotPowerSim">10.5</a> shows an example of how power changes as a function of these factors.</p>
<div class="figure"><span style="display:block;" id="fig:plotPowerSim"></span>
<img src="StatsThinking21_files/figure-html/plotPowerSim-1.png" alt="Results from power simulation, showing power as a function of sample size, with effect sizes shown as different colors, and alpha shown as line type. The standard criterion of 80 percent power is shown by the dotted black line." width="576" height="50%" />
<p class="caption">
Figure 10.5: Results from power simulation, showing power as a function of sample size, with effect sizes shown as different colors, and alpha shown as line type. The standard criterion of 80 percent power is shown by the dotted black line.
</p>
</div>
<p>This simulation shows us that even with a sample size of 96, we will have relatively little power to find a small effect (<span class="math inline">\(d = 0.2\)</span>) with <span class="math inline">\(\alpha = 0.005\)</span>. This means that a study designed to do this would be <em>futile</em> – that is, it is almost guaranteed to find nothing even if a true effect of that size exists.</p>
<p>There are at least two important reasons to care about statistical power. First, if you are a researcher, you probably don’t want to spend your time doing futile experiments. Running an underpowered study is essentially futile, because it means that there is a very low likelihood that one will find an effect, even if it exists. Second, it turns out that any positive findings that come from an underpowered study are more likely to be false compared to a well-powered study, a point we discuss in more detail in Chapter <a href="doing-reproducible-research.html#doing-reproducible-research">18</a>.</p>
<div id="power-analysis" class="section level3 hasAnchor" number="10.3.1">
<h3><span class="header-section-number">10.3.1</span> Power analysis<a href="ci-effect-size-power.html#power-analysis" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Fortunately, there are tools available that allow us to determine the statistical power of an experiment. The most common use of these tools is in planning an experiment, when we would like to determine how large our sample needs to be in order to have sufficient power to find our effect of interest.</p>
<p>Let’s say that we are interested in running a study of how a particular personality trait differs between users of iOS versus Android devices. Our plan is collect two groups of individuals and measure them on the personality trait, and then compare the two groups using a t-test. In this case, we would think that a medium effect (<span class="math inline">\(d = 0.5\)</span>) is of scientific interest, so we will use that level for our power analysis. In order to determine the necessary sample size, we can use power function from our statistical software:</p>
<pre><code>## 
##      Two-sample t test power calculation 
## 
##               n = 64
##           delta = 0.5
##              sd = 1
##       sig.level = 0.05
##           power = 0.8
##     alternative = two.sided
## 
## NOTE: n is number in *each* group</code></pre>
<p>This tells us that we would need at least 64 subjects in each group in order to have sufficient power to find a medium-sized effect. It’s always important to run a power analysis before one starts a new study, to make sure that the study won’t be futile due to a sample that is too small.</p>
<p>It might have occurred to you that if the effect size is large enough, then the necessary sample will be very small. For example, if we run the same power analysis with an effect size of d=2, then we will see that we only need about 5 subjects in each group to have sufficient power to find the difference.</p>
<pre><code>## 
##      Two-sample t test power calculation 
## 
##               n = 5.1
##               d = 2
##       sig.level = 0.05
##           power = 0.8
##     alternative = two.sided
## 
## NOTE: n is number in *each* group</code></pre>
<p>However, it’s rare in science to be doing an experiment where we expect to find such a large effect – just as we don’t need statistics to tell us that 16-year-olds are taller than than 6-year-olds. When we run a power analysis, we need to specify an effect size that is plausible and/or scientifically interesting for our study, which would usually come from previous research. However, in Chapter <a href="doing-reproducible-research.html#doing-reproducible-research">18</a> we will discuss a phenomenon known as the “winner’s curse” that likely results in published effect sizes being larger than the true effect size, so this should also be kept in mind.</p>
</div>
</div>
<div id="learning-objectives-9" class="section level2 hasAnchor" number="10.4">
<h2><span class="header-section-number">10.4</span> Learning objectives<a href="ci-effect-size-power.html#learning-objectives-9" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Having read this chapter, you should be able to:</p>
<ul>
<li>Describe the proper interpretation of a confidence interval, and compute a confidence interval for the mean of a given dataset.</li>
<li>Define the concept of effect size, and compute the effect size for a given test.</li>
<li>Describe the concept of statistical power and why it is important for research.</li>
</ul>
</div>
<div id="suggested-readings-7" class="section level2 hasAnchor" number="10.5">
<h2><span class="header-section-number">10.5</span> Suggested readings<a href="ci-effect-size-power.html#suggested-readings-7" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ul>
<li><a href="http://www.ejwagenmakers.com/inpress/HoekstraEtAlPBR.pdf">Robust misinterpretation of confidence intervals, by Hoekstra et al.</a></li>
</ul>

</div>
</div>
<h3>References<a href="references.html#references" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Neyman37" class="csl-entry">
Neyman, J. 1937. <span>“Outline of a Theory of Statistical Estimation Based on the Classical Theory of Probability.”</span> <em>Philosophical Transactions of the Royal Society of London A: Mathematical, Physical and Engineering Sciences</em> 236 (767): 333–80. <a href="https://doi.org/10.1098/rsta.1937.0005">https://doi.org/10.1098/rsta.1937.0005</a>.
</div>
<div id="ref-pesc:kend:gust:2012" class="csl-entry">
Pesch, Beate, Benjamin Kendzia, Per Gustavsson, Karl-Heinz Jöckel, Georg Johnen, Hermann Pohlabeln, Ann Olsson, et al. 2012. <span>“Cigarette Smoking and Lung Cancer–Relative Risk Estimates for the Major Histological Types from a Pooled Analysis of Case-Control Studies.”</span> <em>Int J Cancer</em> 131 (5): 1210–19. <a href="https://doi.org/10.1002/ijc.27339">https://doi.org/10.1002/ijc.27339</a>.
</div>
<div id="ref-sche:gent:2001" class="csl-entry">
Schenker, Nathaniel, and Jane F. Gentleman. 2001. <span>“On Judging the Significance of Differences by Examining the Overlap Between Confidence Intervals.”</span> <em>The American Statistician</em> 55 (3): 182–86. <a href="http://www.jstor.org/stable/2685796">http://www.jstor.org/stable/2685796</a>.
</div>
<div id="ref-Sullivan:2012ta" class="csl-entry">
Sullivan, Gail M, and Richard Feinn. 2012. <span>“Using Effect Size-or Why the p Value Is Not Enough.”</span> <em>J Grad Med Educ</em> 4 (3): 279–82. <a href="https://doi.org/10.4300/JGME-D-12-00156.1">https://doi.org/10.4300/JGME-D-12-00156.1</a>.
</div>
<div id="ref-wake:1999" class="csl-entry">
Wakefield, A J. 1999. <span>“MMR Vaccination and Autism.”</span> <em>Lancet</em> 354 (9182): 949–50. <a href="https://doi.org/10.1016/S0140-6736(05)75696-8">https://doi.org/10.1016/S0140-6736(05)75696-8</a>.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="hypothesis-testing.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="bayesian-statistics.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="book_assets/gitbook-2.6.7/js/app.min.js"></script>
<script src="book_assets/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="book_assets/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/statsthinking21/statsthinking21-core/edit/master/10-ConfIntEffectSize.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["StatsThinking21.pdf", "StatsThinking21.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
